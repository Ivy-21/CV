{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision, Lab 3: Segmentation\n",
    "\n",
    "Today we'll experiment with methods to segment a scene. Since we've been working with a sample ground robot in an indoor environment, we'll take as an example the task of segmenting unoccupied ground plane space from obstacles.\n",
    "\n",
    "If we can successfully determine which pixels in the image seen by our robot are on the flat floor and which are likely obstacles, we can combine that information with the ground plane homography-based rectification method we developed in the last lab to obtain a map of the space around the robot.\n",
    "\n",
    "The same approach could be used by an autonomous vehicle to determine where, in the image from its front-facing camera, the road is and where possible obstacles are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: Color-based segmentation\n",
    "\n",
    "In our indoor example, we have fairly consistent lighting and a consistently-colored floor, so a color based approach may work.\n",
    "\n",
    "The task here is, given an input pixel at location $(x,y)$ with RGB color $(r,g,b)$, classify the pixel as \"floor\" or \"not floor.\"\n",
    "\n",
    "This is a classic machine learning problem. We have an input feature vector $(r, g, b)$ (some methods would also utilize $x$ and $y$ as well), and a desired output of 1\n",
    "for floor and 0 for non-floor.\n",
    "\n",
    "We probably want to transform the color space from RGB to HSV, since the RGB vector mixes color information with intensity information in the same measurements:\n",
    "\n",
    "<img src=\"img/lab03-1.jpg\" width=\"300\"/>\n",
    "\n",
    "whereas the HSV color space separates color from saturation (\"color purity\") and intensity:\n",
    "\n",
    "<img src=\"img/lab03-2.jpg\" width=\"300\"/>\n",
    "\n",
    "(Images are from Wikimedia Commons via the OpenCV documentation.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we could use a fancy classifier like logistic regression or a SVM, this problem is easily solved with a generative model. We apply the principle of maximum a posteriori classification and Bayes' rule:\n",
    "\n",
    "$$\n",
    "f(h, s, v) = \n",
    "    \\begin{cases}\n",
    "        1 & p(\\text{floor} \\mid h, s, v) > 0.5 \\\\\n",
    "        0 & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(\\text{floor} \\mid h, s, v) = \\frac{p(h, s, v \\mid \\text{floor}) p(\\text{floor})}{p(h, s, v)}\n",
    "$$\n",
    "\n",
    "and since $p(h, s, v)$ is not known, we eliminate it:\n",
    "\n",
    "$$\n",
    "f(h, s, v) =\n",
    "    \\begin{cases}\n",
    "        1 & p(h, s, v \\mid \\text{floor}) p(\\text{floor}) > p(h, s, v | \\text{not floor}) p(\\text{not floor}) \\\\\n",
    "        0 & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "The entity $p(\\text{floor})$ is easy to estimate as the proportion of pixels in a sample of images that are floor pixels.\n",
    "\n",
    "What about $p(h, s, v | floor)$?\n",
    "\n",
    "The simplest approach here is just a lookup table. Since we're conditioning on floor, we just need to sample a bunch of floor pixels and record the frequency of each value of $h$, $s$, and $v$.\n",
    "\n",
    "The problem with that approach is that we'd need something like $10 * 255 * 255 * 255$ pixels (168M!) to get a decent estimate of the value in every bin of this frequency table.\n",
    "\n",
    "What we do instead is collapse some values of $h$, $s$, and $v$ into bins. For example, we might drop the 4 least significant bits of each of these values, then we'd end up needing only about $10 * 16 * 16 * 16$ (just 41K) samples to get a decent estimate.\n",
    "\n",
    "Note that some methods would further drop the V element, which represents intensity, on the assumption that the global amount of lighting doesn't matter.\n",
    "\n",
    "In fact, as the sun moves across the sky, the color composition of the light changes, and artificial light is quite different in color than sunlight. Still, it's a start.\n",
    "\n",
    "So we want to collapse the $(h, s, v)$ vector into two features, $(h>>4, s>>4)$. We'll end up with a lookup table containing just $16*16 = 256$ elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and save an image-plane-to-ground-plane homography to a YML file\n",
    "\n",
    "Let's use a simple version of the program from lab 2 that calls `getPerspectiveTransform()`\n",
    "to get a ground plane to image plane homography and save it to a YML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <opencv2/opencv.hpp>\n",
    "\n",
    "using namespace cv;\n",
    "using namespace std;\n",
    "\n",
    "#define VIDEO_FILE \"robot.mp4\"\n",
    "#define HOMOGRAPHY_FILE \"robot-homography.yml\"\n",
    "\n",
    "Mat matPauseScreen, matResult, matFinal;\n",
    "Point point;\n",
    "vector<Point> pts;\n",
    "int var = 0;\n",
    "int drag = 0;\n",
    "\n",
    "// Create mouse handler function\n",
    "void mouseHandler(int event, int x, int y, int, void*)\n",
    "{\n",
    "    if (var >= 4) return;\n",
    "    if (event == EVENT_LBUTTONDOWN) // Left button down\n",
    "    {\n",
    "        drag = 1;\n",
    "        matResult = matFinal.clone();\n",
    "        point = Point(x, y);\n",
    "        if (var >= 1) \n",
    "        {\n",
    "            line(matResult, pts[var - 1], point, Scalar(0, 255, 0, 255), 2);\n",
    "        }\n",
    "        circle(matResult, point, 2, Scalar(0, 255, 0), -1, 8, 0);\n",
    "        imshow(\"Source\", matResult);\n",
    "    }\n",
    "    if (event == EVENT_LBUTTONUP && drag) // When Press mouse left up\n",
    "    {\n",
    "        drag = 0; var++;\n",
    "        pts.push_back(point);\n",
    "        matFinal = matResult.clone();\n",
    "        if (var >= 4)\n",
    "        {\n",
    "            line(matFinal, pts[0], pts[3], Scalar(0, 255, 0, 255), 2);\n",
    "            fillPoly(matFinal, pts, Scalar(0, 120, 0, 20), 8, 0);\n",
    "\n",
    "            setMouseCallback(\"Source\", NULL, NULL);\n",
    "        }\n",
    "        imshow(\"Source\", matFinal);\n",
    "    }\n",
    "    if (drag)\n",
    "    {\n",
    "        matResult = matFinal.clone();\n",
    "        point = Point(x, y);\n",
    "        if (var >= 1) \n",
    "            line(matResult, pts[var - 1], point, Scalar(0, 255, 0, 255), 2);\n",
    "        circle(matResult, point, 2, Scalar(0, 255, 0), -1, 8, 0);\n",
    "        imshow(\"Source\", matResult);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    Mat matFrameCapture;\n",
    "    Mat matFrameDisplay;\n",
    "    int key = -1;\n",
    "\n",
    "    VideoCapture videoCapture(VIDEO_FILE);\n",
    "    if (!videoCapture.isOpened()) {\n",
    "        cerr << \"ERROR! Unable to open input video file \" << VIDEO_FILE << endl;\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    while (key < 0)        // play video until press any key\n",
    "    {\n",
    "        // Get the next frame\n",
    "        videoCapture.read(matFrameCapture);\n",
    "        if (matFrameCapture.empty()) {\n",
    "            // End of video file\n",
    "            break;\n",
    "        }\n",
    "        float ratio = 640.0 / matFrameCapture.cols;\n",
    "        resize(matFrameCapture, matFrameDisplay, cv::Size(), ratio, ratio, INTER_LINEAR);\n",
    "\n",
    "        imshow(VIDEO_FILE, matFrameDisplay);\n",
    "        key = waitKey(30);\n",
    "\n",
    "        if (key >= 0)\n",
    "        {\n",
    "            destroyWindow(VIDEO_FILE);\n",
    "            matPauseScreen = matFrameCapture;\n",
    "            matFinal = matPauseScreen.clone();\n",
    "\n",
    "            namedWindow(\"Source\", WINDOW_AUTOSIZE);\n",
    "            setMouseCallback(\"Source\", mouseHandler, NULL);\n",
    "            imshow(\"Source\", matPauseScreen);\n",
    "            waitKey(0);\n",
    "            destroyWindow(\"Source\");\n",
    "\n",
    "            Point2f src[4];\n",
    "            for (int i = 0; i < 4; i++)\n",
    "            {\n",
    "                src[i].x = pts[i].x * 1.0;\n",
    "                src[i].y = pts[i].y * 1.0;\n",
    "            }\n",
    "            Point2f reals[4];\n",
    "            reals[0] = Point2f(800.0, 800.0);\n",
    "            reals[1] = Point2f(1000.0, 800.0);\n",
    "            reals[2] = Point2f(1000.0, 1000.0);\n",
    "            reals[3] = Point2f(800.0, 1000.0);\n",
    "\n",
    "            Mat homography_matrix = getPerspectiveTransform(src, reals);\n",
    "            std::cout << \"Estimated Homography Matrix is:\" << std::endl;\n",
    "            std::cout << homography_matrix << std::endl;\n",
    "\n",
    "            // perspective transform operation using transform matrix\n",
    "            cv::warpPerspective(matPauseScreen, matResult, homography_matrix, matPauseScreen.size(), cv::INTER_LINEAR);\n",
    "            imshow(\"Source\", matPauseScreen);\n",
    "            imshow(\"Result\", matResult);\n",
    "\n",
    "            waitKey(0);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "VIDEO_FILE = \"robot.mp4\"\n",
    "HOMOGRAPHY_FILE = \"robot-homography.yml\"\n",
    "\n",
    "matResult = None\n",
    "matFinal = None\n",
    "matPauseScreen = None\n",
    "\n",
    "point = (-1, -1)\n",
    "pts = []\n",
    "var = 0 \n",
    "drag = 0\n",
    "\n",
    "# Mouse handler function has 5 parameters input (no matter what)\n",
    "def mouseHandler(event, x, y, flags, param):\n",
    "    global point, pts, var, drag, matFinal, matResult\n",
    "\n",
    "    if (var >= 4):                           # if homography points are more than 4 points, do nothing\n",
    "        return\n",
    "    if (event == cv2.EVENT_LBUTTONDOWN):     # When Press mouse left down\n",
    "        drag = 1                             # Set it that the mouse is in pressing down mode\n",
    "        matResult = matFinal.copy()          # copy final image to draw image\n",
    "        point = (x, y)                       # memorize current mouse position to point var\n",
    "        if (var >= 1):                       # if the point has been added more than 1 points, draw a line\n",
    "            cv2.line(matResult, pts[var - 1], point, (0, 255, 0, 255), 2)    # draw a green line with thickness 2\n",
    "        cv2.circle(matResult, point, 2, (0, 255, 0), -1, 8, 0)             # draw a current green point\n",
    "        cv2.imshow(\"Source\", matResult)      # show the current drawing\n",
    "    if (event == cv2.EVENT_LBUTTONUP and drag):  # When Press mouse left up\n",
    "        drag = 0                             # no more mouse drag\n",
    "        pts.append(point)                    # add the current point to pts\n",
    "        var += 1                             # increase point number\n",
    "        matFinal = matResult.copy()          # copy the current drawing image to final image\n",
    "        if (var >= 4):                                                      # if the homograpy points are done\n",
    "            cv2.line(matFinal, pts[0], pts[3], (0, 255, 0, 255), 2)   # draw the last line\n",
    "            cv2.fillConvexPoly(matFinal, np.array(pts, 'int32'), (0, 120, 0, 20))        # draw polygon from points\n",
    "        cv2.imshow(\"Source\", matFinal);\n",
    "    if (drag):                                    # if the mouse is dragging\n",
    "        matResult = matFinal.copy()               # copy final images to draw image\n",
    "        point = (x, y)                            # memorize current mouse position to point var\n",
    "        if (var >= 1):                            # if the point has been added more than 1 points, draw a line\n",
    "            cv2.line(matResult, pts[var - 1], point, (0, 255, 0, 255), 2)    # draw a green line with thickness 2\n",
    "        cv2.circle(matResult, point, 2, (0, 255, 0), -1, 8, 0)         # draw a current green point\n",
    "        cv2.imshow(\"Source\", matResult)           # show the current drawing\n",
    "\n",
    "def main():\n",
    "    global matFinal, matResult, matPauseScreen\n",
    "    key = -1;\n",
    "\n",
    "    videoCapture = cv2.VideoCapture(VIDEO_FILE)\n",
    "    if not videoCapture.isOpened():\n",
    "        print(\"ERROR! Unable to open input video file \", VIDEO_FILE)\n",
    "        return -1\n",
    "\n",
    "    width  = videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
    "    height = videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
    "\n",
    "    # Capture loop \n",
    "    while (key < 0):\n",
    "        # Get the next frame\n",
    "        _, matFrameCapture = videoCapture.read()\n",
    "        if matFrameCapture is None:\n",
    "            # End of video file\n",
    "            break\n",
    "\n",
    "        ratio = 640.0 / width\n",
    "        dim = (int(width * ratio), int(height * ratio))\n",
    "        matFrameDisplay = cv2.resize(matFrameDisplay, dim)\n",
    "\n",
    "        cv2.imshow(VIDEO_FILE, matFrameDisplay)\n",
    "        key = cv2.waitKey(30)\n",
    "\n",
    "        if (key >= 0):\n",
    "            cv2.destroyWindow(VIDEO_FILE)\n",
    "            matPauseScreen = matFrameCapture\n",
    "            matFinal = matPauseScreen.copy()\n",
    "            cv2.namedWindow(\"Source\", cv2.WINDOW_AUTOSIZE)\n",
    "            cv2.setMouseCallback(\"Source\", mouseHandler)\n",
    "            cv2.imshow(\"Source\", matPauseScreen)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyWindow(\"Source\")\n",
    "\n",
    "            if (len(pts) < 4):\n",
    "                return\n",
    "\n",
    "            src = np.array(pts).astype(np.float32)\n",
    "            reals = np.array([(800, 800),\n",
    "                                (1000, 800),\n",
    "                                (1000, 1000),\n",
    "                                (800, 1000)], np.float32)\n",
    "\n",
    "            homography_matrix = cv2.getPerspectiveTransform(src, reals);\n",
    "            print(\"Estimated Homography Matrix is:\")\n",
    "            print(homography_matrix)\n",
    "\n",
    "            h, w, ch = matPauseScreen.shape\n",
    "            matResult = cv2.warpPerspective(matPauseScreen, homography_matrix, (w, h), cv2.INTER_LINEAR)\n",
    "            matPauseScreen = cv2.resize(matPauseScreen, dim)\n",
    "            cv2.imshow(\"Source\", matPauseScreen)\n",
    "            matResult = cv2.resize(matResult, dim)\n",
    "            cv2.imshow(\"Result\", matResult)\n",
    "\n",
    "            cv2.waitKey(0)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a class for reading/writing homography data\n",
    "\n",
    "Let's make a structure for our homography data. Objects\n",
    "of class <code>HomographyData</code> will keep the information about a homography. It contains:\n",
    "\n",
    "- cPoints: number of points for setting homography\n",
    "- aPoints: points information\n",
    "- matH: Homography matrix\n",
    "- widthOut: image width of the output image\n",
    "- heightOut: image height of the output image\n",
    "\n",
    "We need two methods: reading and writing homographies.\n",
    "\n",
    "At this step, you should create a new cpp file for create the special functions and structure. Please create 2 files: <code>HomographyData.h</code> and <code>HomographyData.cpp</code>\n",
    "\n",
    "For Visual Studio users: <code>HomographyData.h</code> should be created in your\n",
    "\"Header Files\" section, and <code>HomographyData.cpp</code> should be created in\n",
    "your \"Source Files\" section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++ header\n",
    "\n",
    "Place the following in `HomographyData.h`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <opencv2/opencv.hpp>\n",
    "\n",
    "class HomographyData\n",
    "{\n",
    "public:\n",
    "    cv::Mat matH;\n",
    "    int widthOut;\n",
    "    int heightOut;\n",
    "    int cPoints;\n",
    "    cv::Point2f aPoints[4];\n",
    "\n",
    "    HomographyData();\n",
    "    HomographyData(std::string homography_file);\n",
    "\n",
    "    bool read(std::string homography_file);\n",
    "    bool write(std::string homography_file);\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++ source file\n",
    "\n",
    "Then provide the implementation in `HomographyData.cpp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include \"homography.h\"\n",
    "\n",
    "Homography::Homography(std::string homography_file)\n",
    "{\n",
    "    read(homography_file);\n",
    "}\n",
    "\n",
    "HomographyData::HomographyData()\n",
    "{\n",
    "    cPoints = 0;\n",
    "}\n",
    "\n",
    "bool HomographyData::read(std::string homography_file)\n",
    "{\n",
    "    cv::FileStorage fileStorage(homography_file, cv::FileStorage::Mode::READ);\n",
    "    if (!fileStorage.isOpened()) {\n",
    "        return false;\n",
    "    }\n",
    "    cv::FileNode points = fileStorage[\"aPoints\"];\n",
    "    cv::FileNodeIterator it = points.begin(), it_end = points.end();\n",
    "    cPoints = 0;\n",
    "    for (int i = 0; it != it_end; it++, i++) {\n",
    "        (*it) >> aPoints[i];\n",
    "        cPoints++;\n",
    "    }\n",
    "    fileStorage[\"matH\"] >> matH;\n",
    "    fileStorage[\"widthOut\"] >> widthOut;\n",
    "    fileStorage[\"heightOut\"] >> heightOut;\n",
    "    fileStorage.release();\n",
    "    return true;\n",
    "}\n",
    "\n",
    "bool HomographyData::write(std::string homography_file)\n",
    "{\n",
    "    cv::FileStorage fileStorage(homography_file, cv::FileStorage::Mode::WRITE);\n",
    "    if (!fileStorage.isOpened()) {\n",
    "        return false;\n",
    "    }\n",
    "\n",
    "    fileStorage << \"aPoints\" << \"[\";\n",
    "    for (int i = 0; i < 4; i++)\n",
    "    {\n",
    "        fileStorage << aPoints[i];\n",
    "    }\n",
    "    fileStorage << \"]\";\n",
    "    fileStorage << \"matH\" << matH;\n",
    "    fileStorage << \"widthOut\" << widthOut;\n",
    "    fileStorage << \"heightOut\" << heightOut;\n",
    "    fileStorage.release();\n",
    "    return true;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List #use it for :List[...]\n",
    "\n",
    "class Homograpy:\n",
    "    matH = np.zeros((3, 3))\n",
    "    widthOut : int\n",
    "    heightOut : int\n",
    "    cPoints : int\n",
    "    aPoints:list = []\n",
    "\n",
    "    def __init__(self, homography_file = None):\n",
    "        self.cPoints = 0\n",
    "        if homography_file is not None:\n",
    "            self.read(homography_file)\n",
    "\n",
    "    def read(self, homography_file):\n",
    "        fileStorage = cv2.FileStorage(homography_file, cv2.FILE_STORAGE_READ)\n",
    "        if not fileStorage.isOpened():\n",
    "            return False\n",
    "\n",
    "        self.cPoints = 0\n",
    "        for i in range(points.size()):\n",
    "            points = fileStorage.getNode(\"aPoints\" + str(i))\n",
    "            self.aPoints.append(points.mat())\n",
    "            self.cPoints += 1\n",
    "        self.matH = fileStorage.getNode(\"matH\").mat()\n",
    "        self.widthOut = int(fileStorage.getNode(\"widthOut\").real())\n",
    "        self.heightOut = int(fileStorage.getNode(\"heightOut\").real())\n",
    "        fileStorage.release()\n",
    "        return True\n",
    "\n",
    "    def write(self, homography_file):\n",
    "        fileStorage = cv2.FileStorage(homography_file, cv2.FILE_STORAGE_WRITE)\n",
    "        if not fileStorage.isOpened():\n",
    "            return False\n",
    "\n",
    "        for i in range(4):\n",
    "            fileStorage.write(\"aPoints\" + str(i), self.aPoints[i])\n",
    "\n",
    "        fileStorage.write(\"matH\", self.matH)\n",
    "        fileStorage.write(\"widthOut\", self.widthOut)\n",
    "        fileStorage.write(\"heightOut\", self.heightOut)\n",
    "        fileStorage.release()\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using it in C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include \"HomographyData.h\"\n",
    "\n",
    "...\n",
    "\n",
    "// Write H to file\n",
    "\n",
    "HomographyData homographyData;\n",
    "for (int i = 0; i < 4; i++)\n",
    "{\n",
    "    homographyData.aPoints[i] = src[i];\n",
    "    homographyData.cPoints++;\n",
    "}\n",
    "homographyData.matH = homography_matrix;\n",
    "homographyData.widthOut = matPauseScreen.cols;\n",
    "homographyData.heightOut = matPauseScreen.rows;\n",
    "if (!homographyData.write(HOMOGRAPHY_FILE)) {\n",
    "    cerr << \"ERROR! Unable to write homography data file \" << HOMOGRAPHY_FILE << endl;\n",
    "    return -1;\n",
    "}\n",
    "\n",
    "...\n",
    "\n",
    "// Read H from file\n",
    "\n",
    "HomographyData homographyData(HOMOGRAPHY_FILE);\n",
    "if (!homographyData.cPoints == 0) {\n",
    "    cerr << \"ERROR! Unable to read homography data file \" << HOMOGRAPHY_FILE << endl;\n",
    "    return -1;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using it in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write H to file\n",
    "\n",
    "homographyData = Homography()\n",
    "homographyData.cPoints = 0\n",
    "for i in range(4):\n",
    "    homographyData.aPoints.append(src[i])\n",
    "    homographyData.cPoints += 1\n",
    "homographyData.matH = homography_matrix\n",
    "homographyData.widthOut = width\n",
    "homographyData.heightOut = height\n",
    "homographyData.write(HOMOGRAPHY_FILE)\n",
    "\n",
    "...\n",
    "\n",
    "# Read H from file\n",
    "\n",
    "homographyData = Homography(HOMOGRAPHY_FILE)\n",
    "if homographyData.cPoints == 0:\n",
    "    print(\"ERROR! Unable to read homography data file \", HOMOGRAPHY_FILE)\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "The output file `robot-homography.yml` might contain the following. This is from the Python version; the C++ version is slightly\n",
    "different.\n",
    "\n",
    "    %YAML:1.0\n",
    "    ---\n",
    "    aPoints0: !!opencv-matrix\n",
    "       rows: 2\n",
    "       cols: 1\n",
    "       dt: d\n",
    "       data: [ 860., 49. ]\n",
    "    aPoints1: !!opencv-matrix\n",
    "       rows: 2\n",
    "       cols: 1\n",
    "       dt: d\n",
    "       data: [ 1386., 52. ]\n",
    "    aPoints2: !!opencv-matrix\n",
    "       rows: 2\n",
    "       cols: 1\n",
    "       dt: d\n",
    "       data: [ 1620., 375. ]\n",
    "    aPoints3: !!opencv-matrix\n",
    "       rows: 2\n",
    "       cols: 1\n",
    "       dt: d\n",
    "       data: [ 784., 367. ]\n",
    "    matH: !!opencv-matrix\n",
    "       rows: 3\n",
    "       cols: 3\n",
    "       dt: d\n",
    "       data: [ -1.1391186748382573e-03, -2.2794919900117339e-03,\n",
    "           1.0627648167793186e-16, 1.6604445559011895e-05,\n",
    "           -3.2917310423991194e-03, -3.1863931027743840e-02,\n",
    "           -1.6241141452077307e-09, -1.8250980274059071e-06,\n",
    "           -9.0126408686546570e-04 ]\n",
    "    widthOut: 2419\n",
    "    heightOut: 1250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a pre-computed homography in a new program\n",
    "\n",
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <opencv2/opencv.hpp>\n",
    "#include <iostream>\n",
    "#include \"homography.h\"\n",
    "\n",
    "using namespace cv;\n",
    "using namespace std;\n",
    "\n",
    "#define VIDEO_FILE \"robot.mp4\"\n",
    "#define HOMOGRAPHY_FILE \"robot-homography.yml\"\n",
    "\n",
    "void displayFrame(cv::Mat& matFrameDisplay, int iFrame, int cFrames, tsHomographyData* pHomographyData) {\n",
    "    for (int i = 0; i < pHomographyData->cPoints; i++) {\n",
    "        cv::circle(matFrameDisplay, pHomographyData->aPoints[i], 10, cv::Scalar(255, 0, 0), 2, cv::LINE_8, 0);\n",
    "    }\n",
    "    imshow(VIDEO_FILE, matFrameDisplay);\n",
    "    stringstream ss;\n",
    "    ss << \"Frame \" << iFrame << \"/\" << cFrames;\n",
    "    ss << \": hit <space> for next frame or 'q' to quit\";\n",
    "    //cv::displayOverlay(VIDEO_FILE, ss.str(), 0);  // for linux + qt\n",
    "    putText(matFrameDisplay, ss.str(), Point(10, 30), FONT_HERSHEY_SIMPLEX, 1.0, Scalar(0, 0, 255), 3);\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    cv::Mat matFrameCapture;\n",
    "    cv::Mat matFrameDisplay;\n",
    "    int cFrames;\n",
    "    tsHomographyData homographyData;\n",
    "\n",
    "    cv::VideoCapture videoCapture(VIDEO_FILE);\n",
    "    if (!videoCapture.isOpened()) {\n",
    "        cerr << \"ERROR! Unable to open input video file \" << VIDEO_FILE << endl;\n",
    "        return -1;\n",
    "    }\n",
    "    cFrames = (int)videoCapture.get(cv::CAP_PROP_FRAME_COUNT);\n",
    "\n",
    "    // Create a named window that will be used later to display each frame\n",
    "    cv::namedWindow(VIDEO_FILE, (unsigned int)cv::WINDOW_NORMAL | cv::WINDOW_KEEPRATIO | cv::WINDOW_GUI_EXPANDED);\n",
    "\n",
    "    // Read homography from file\n",
    "    if (!readHomography(HOMOGRAPHY_FILE, &homographyData)) {\n",
    "        cerr << \"ERROR! Unable to read homography data file \" << HOMOGRAPHY_FILE << endl;\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    int iFrame = 0;\n",
    "    while (true) {\n",
    "\n",
    "        // Block for next frame\n",
    "\n",
    "        videoCapture.read(matFrameCapture);\n",
    "        if (matFrameCapture.empty()) {\n",
    "            // End of video file\n",
    "            break;\n",
    "        }\n",
    "\n",
    "        displayFrame(matFrameCapture, iFrame, cFrames, &homographyData);\n",
    "\n",
    "        int iKey;\n",
    "        do {\n",
    "            iKey = cv::waitKey(10);\n",
    "            if (getWindowProperty(VIDEO_FILE, cv::WND_PROP_VISIBLE) == 0) {\n",
    "                return 0;\n",
    "            }\n",
    "            if (iKey == (int)'q' || iKey == (int)'Q') {\n",
    "                return 0;\n",
    "            }\n",
    "        } while (iKey != (int)' ');\n",
    "        iFrame++;\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from homography import tsHomographyData, readHomography, writeHomography\n",
    "\n",
    "VIDEO_FILE = \"robot.mp4\"\n",
    "HOMOGRAPHY_FILE = \"robot-homography.yml\"\n",
    "\n",
    "def displayFrame(matFrameDisplay, iFrame, cFrames, pHomographyData):\n",
    "    for i in range(pHomographyData.cPoints):\n",
    "        cv2.circle(matFrameDisplay, pHomographyData.aPoints[i], 10, (255, 0, 0), 2, cv.LINE_8, 0)\n",
    "\n",
    "    cv2.imshow(VIDEO_FILE, matFrameDisplay)\n",
    "    ss = \"Frame \" + str(iFrame) + \"/\" + str(cFrames)\n",
    "    ss += \": hit <space> for next frame or 'q' to quit\";\n",
    "    # cv2.displayOverlay(VIDEO_FILE, ss, 0);  # for linux + qt\n",
    "    cv2.putText(matFrameDisplay, ss, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3);\n",
    "\n",
    "def main():\n",
    "    global matFinal, matResult, matPauseScreen\n",
    "    key = -1;\n",
    "\n",
    "    videoCapture = cv2.VideoCapture(VIDEO_FILE)\n",
    "    if not videoCapture.isOpened():\n",
    "        print(\"ERROR! Unable to open input video file \", VIDEO_FILE)\n",
    "        return -1\n",
    "\n",
    "    width  = videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
    "    height = videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
    "\n",
    "    cFrames = videoCapture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    cv2.namedWindow(VIDEO_FILE, cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO | cv2.WINDOW_GUI_EXPANDED)\n",
    "\n",
    "    homographyData = readHomography(HOMOGRAPHY_FILE)\n",
    "    if homographyData is None:\n",
    "        print(\"ERROR! Unable to read homography data file \", HOMOGRAPHY_FILE)\n",
    "        return -1\n",
    "\n",
    "    iFrame = 0\n",
    "    # Capture loop \n",
    "    while (key < 0):\n",
    "        # Get the next frame\n",
    "        _, matFrameCapture = videoCapture.read()\n",
    "        if matFrameCapture is None:\n",
    "            # End of video file\n",
    "            break\n",
    "\n",
    "        matFrameCapture = videoCapture.read(matFrameCapture)\n",
    "        if matFrameCapture is None:\n",
    "            # End of video file\n",
    "            break\n",
    "\n",
    "        displayFrame(matFrameCapture, iFrame, cFrames, homographyData)\n",
    "\n",
    "        iKey = -1\n",
    "        while iKey != ord(' '):\n",
    "            iKey = cv2.waitKey(10)\n",
    "            if (getWindowProperty(VIDEO_FILE, cv2.WND_PROP_VISIBLE) == 0):\n",
    "                return 0\n",
    "            if (iKey == ord('q') or iKey == ord('Q')):\n",
    "                return 0\n",
    "\n",
    "        iFrame += 1\n",
    "\n",
    "        return\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick version of segmentation\n",
    "\n",
    "As a simple experiment, find a pixel in the image that is clearly on the floor, then\n",
    "convert the input image to the HSV colorspace using code\n",
    "\n",
    "    cvtColor(matFrameBGR, matFrameHSV, COLOR_BGR2HSV);\n",
    "\n",
    "If you display HSV as an image you might get something like this:\n",
    "\n",
    "<img src=\"img/lab03-4.png\" width=\"600\"/>\n",
    "\n",
    "Output the HSV values at your preferred location. Create a 2D array <code>double aProbFloorHS[16][16]</code>\n",
    "and set the selected bin to a probability of 1.0 and all others to 0.\n",
    "Show, in a second window, a mask for the pixels selected by $p(h, s, v \\mid \\text{floor}) > 0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain HS probabilities using a machine learning model\n",
    "\n",
    "Next, take the first frame from the video, load it in <link>[gimp](https://www.gimp.org/downloads/)</link> or other image editing software, and make a mask for the floor pixels.\n",
    "\n",
    "To extract frames from the video at a frame rate of one frame per second of the video, try at the command line\n",
    "\n",
    "    $ sudo apt-get install ffmpeg\n",
    "    $ ffmpeg -i robot.mp4 -r 1 -f image2 frame-%03d.png\n",
    "\n",
    "Or you can save an image sequence from your OpenCV program:\n",
    "\n",
    "    stringstream ss;\n",
    "    ss << fixed << setprecision(3) << setfill('0');     // set fix digit prefix length to 3 and the blank digit is filled by 0\n",
    "    ss << \"frame-\" << setw(3) << iFrame << \".png\";      // set iFrame length to 3 from command above\n",
    "    imwrite(ss.str(), matFrameCapture);\n",
    "\n",
    "To make a mask in gimp, add a 50% transparent layer, color pixels you want to select, and delete the original image layer with: \n",
    "\n",
    "(right click $\\rightarrow$ Layer $\\rightarrow$ Stack $\\rightarrow$ Select Next Layer), and then\n",
    "\n",
    "(right click $\\rightarrow$ Layer $\\rightarrow$ Delete Layer).\n",
    "\n",
    "<img src=\"img/lab03-5.png\" width=\"300\"/>\n",
    "\n",
    "<img src=\"img/lab03-6.png\" width=\"600\"/>\n",
    "\n",
    "<img src=\"img/lab03-7.png\" width=\"600\"/>\n",
    "\n",
    "You can copy the resulting layer then create a new image from the clipboard and export as a black and white PNG.\n",
    "\n",
    "<img src=\"img/lab03-8.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add code to your program to read a mask along with the corresponding frame, apply the mask to the first frame of the video,\n",
    "and accumulalte the entries in the <code>aProbFloorHS</code> array. You'll also need a <code>aProbNonFloorHS</code> array and\n",
    "total pixel counts for each array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent exercise: Try to get a good probabilistic floor color model yourself\n",
    "\n",
    "Finally, display the mask in a partially transparent color on top of the image as the video is rendered. How well does it work? You might want to add additional images to your training set. Consider a tool such as hasty.ai to mark up multiple images.\n",
    "\n",
    "With a training set of 19 images, 64 bins for H, 16 bins for S, and 16 bins for V, I got a leave-one-out cross validated test accuracy of around 95%, with an F1 for the floor of 0.98 and an F1 for the obstacles of 0.51. See how well your model works and include this information in your report.\n",
    "\n",
    "## The report\n",
    "\n",
    "You should turn in, before the next lab, a brief report of your experiments and results. Also upload a video showing off your results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
