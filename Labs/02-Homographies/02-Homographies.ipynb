{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision, Lab 2: Homographies\n",
    "\n",
    "In computer vision, the most important geometric transformations are\n",
    "2D planar homographies, 3D Euclidean homographies, and 3D similarity homographies.\n",
    "\n",
    "Although you will be limited to a single scene plane,\n",
    "a 2D planar homography is the simplest way to get 3D information from a 2D image.\n",
    "\n",
    "Today we'll boost our OpenCV programming skills and learn how to do the math we\n",
    "learned in class using code.\n",
    "\n",
    "## GUI programing in OpenCV\n",
    "\n",
    "To display the results of your calculations, you'll need to be able to visualize\n",
    "images from a camera or video and draw on them. In OpenCV, these capabilities use the\n",
    "\"HighGUI\" and \"ImgProc\" libraries. For showing images, we use the following important\n",
    "functions:\n",
    "\n",
    " - <code>imshow()</code>: Show an image in a window. If you use the same name as an existing window, the image will replace the old image in the same window.\n",
    " - <code>waitKey()</code>: Wait for the user to press a key indefinitely or until a timer expires. Since image display runs in a separate thread that you\n",
    "   don't (usually) control, your main thread needs to pause briefly to give time for display. <code>waitKey()</code> is a good way to do this, as it will\n",
    "   put the calling thread to sleep for the given number of milliseconds. 1 ms is plenty of time for the display thread to do its work. If you have other\n",
    "   actions that block the main thread such as waiting for the next image to be captured and transferred to RAM by a camera driver and you don't need user\n",
    "   input, you don't need to use <code>waitKey()</code>.\n",
    " - <code>destroyWindow()</code>: Destroy a target window.\n",
    " - <code>destroyAllWindows()</code>: Destroy all windows under the program's control.\n",
    " \n",
    "Let's start with a simple version of our solution.\n",
    "\n",
    "### Tip on loading files before starting\n",
    "\n",
    "Depending on how your program is started when testing it, it will always have a specific working directory.\n",
    "\n",
    "If you want to open files by filename only without a full path, you'll need to put them in the program's working directory\n",
    "or change the working directory to point to where the files are.\n",
    "\n",
    "**Windows Visual Studio C++**: Put resources such as images and videos in the same directory as your <code>.cpp</code> source code.\n",
    "\n",
    "For example, suppose we create a project named <code>Samplelab2</code> under <code>C:\\Users\\alisa\\source\\repos</code>.\n",
    "The <code>.cpp</code> file containing the main function is in\n",
    "<code>C:\\Users\\alisa\\source\\repos\\Samplelab2\\Samplelab2</code>, so we should put the image file <code>lena.png</code> as below:\n",
    "\n",
    "<img src=\"img/lab02-1.PNG\" width=\"600\"/>\n",
    "\n",
    "By the way, we shouldn't use the image <tt>lena.png</tt>, even though it is convenient and ships with\n",
    "the OpenCV source code. [Read some of the context in Wikipedia](https://en.wikipedia.org/wiki/Lenna).\n",
    "The image comes from a pornographic magazine, *Playboy*, from the 1970s,\n",
    "and its continued use in the image processing community is given as\n",
    "an example of sexism in the sciences, reinforcing gender stereotypes.\n",
    "\n",
    "So while we're being nostalgic, [here's a better image from the 1970s](img/sample.jpg).\n",
    "Anyway, once you put it in the right place, your program your program can refer to the file without a full path:\n",
    "\n",
    "    Mat srcImage = imread(\"sample.jpg\");\n",
    "\n",
    "However, if you run the executable from another directory, you'll have to put the resource in the directory you're running from.\n",
    "\n",
    "**Python**: Use the same idea as above.\n",
    "\n",
    "**Linux**: Find out how your IDE sets the working directory when you run, or put the resource in the build directory, or use a relative\n",
    "path to run the executable from the directory where the resource is located.\n",
    "\n",
    "### Show an image in C++\n",
    "\n",
    "Here's some code to show an image. Get [<tt>sample.jpg</tt> from here](img/sample.jpg).\n",
    "\n",
    "    #include <iostream>\n",
    "    #include <opencv2/opencv.hpp> // This includes all of OpenCV. You could use just opencv2/highgui.hpp.\n",
    "\n",
    "    using namespace cv;           // Without this you would have to prefix every OpenCV call with cv::\n",
    "    using namespace std;          // Without this you would have to prefix every C++ standard library call with std::\n",
    "\n",
    "    int main(int argc, char* argv[])\n",
    "    {\n",
    "        int iKey = -1;\n",
    "        string sFilename = \"sample.jpg\";\n",
    "        Mat matImage = imread(sFilename);\n",
    "        if (matImage.empty())\n",
    "        {\n",
    "            cout << \"No image to show\" << endl;\n",
    "            return 1;\n",
    "        }\n",
    "        imshow(\"Input image\", matImage);\n",
    "        // Wait up to 5s for a keypress\n",
    "        iKey = waitKey(5000);\n",
    "        cout << \"Key output value: \" << iKey << endl;    \n",
    "        return 0;\n",
    "    }\n",
    "\n",
    "### Show an image in Python\n",
    "\n",
    "Things are a bit simpler in Python:\n",
    "\n",
    "    import cv2\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        path = 'sample.jpg'\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print('No image to show')\n",
    "        else\n",
    "            cv2.imshow('Input image', img)\n",
    "            # Wait up to 5s for a keypress\n",
    "            cv2.waitKey(5000);\n",
    "\n",
    "### Show a video in C++\n",
    "\n",
    "Here's how to show a video in C++:\n",
    "\n",
    "    #include <opencv2/opencv.hpp>\n",
    "    #include <iostream>\n",
    "\n",
    "    using namespace cv;\n",
    "    using namespace std;\n",
    "\n",
    "    // In C++, you can define constants variable using #define\n",
    "    #define VIDEO_FILE \"robot.mp4\"\n",
    "    #define ROTATE false\n",
    "\n",
    "    int main(int argc, char** argv)\n",
    "    {\n",
    "        Mat matFrameCapture;\n",
    "        Mat matFrameDisplay;\n",
    "        int iKey = -1;\n",
    "\n",
    "        // Open input video file\n",
    "        VideoCapture videoCapture(VIDEO_FILE);\n",
    "        if (!videoCapture.isOpened()) {\n",
    "            cerr << \"ERROR! Unable to open input video file \" << VIDEO_FILE << endl;\n",
    "            return -1;\n",
    "        }\n",
    "\n",
    "        // Capture loop\n",
    "        while (iKey != int(' '))        // play video until user presses <space>\n",
    "        {\n",
    "            // Get the next frame\n",
    "            videoCapture.read(matFrameCapture);\n",
    "            if (matFrameCapture.empty())\n",
    "            {\n",
    "                // End of video file\n",
    "                break;\n",
    "            }\n",
    "\n",
    "            // We can rotate the image easily if needed.\n",
    "    #if ROTATE\n",
    "            rotate(matFrameCapture, matFrameDisplay, RotateFlags::ROTATE_180);   //rotate 180 degree and put the image to matFrameDisplay\n",
    "    #else\n",
    "            matFrameDisplay = matFrameCapture;\n",
    "    #endif\n",
    "\n",
    "            float ratio = 480.0 / matFrameDisplay.rows;\n",
    "            resize(matFrameDisplay, matFrameDisplay, cv::Size(), ratio, ratio, INTER_LINEAR); // resize image to 480p for showing\n",
    "\n",
    "            // Display\n",
    "            imshow(VIDEO_FILE, matFrameDisplay); // Show the image in window named \"robot.mp4\"\n",
    "            iKey = waitKey(30); // Wait 30 ms to give a realistic playback speed\n",
    "        }\n",
    "        return 0;\n",
    "    }\n",
    "\n",
    "### Show a video in Python\n",
    "\n",
    "Now let's do the same in Python:\n",
    "\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import sys\n",
    "\n",
    "    VIDEO_FILE = 'robot.mp4'\n",
    "    ROTATE = False\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "    \n",
    "        key = -1;\n",
    "\n",
    "        # Open input video file\n",
    "        videoCapture = cv2.VideoCapture(VIDEO_FILE);\n",
    "        if not videoCapture.isOpened():\n",
    "            print('Error: Unable to open input video file', VIDEO_FILE)\n",
    "            sys.exit('Unable to open input video file')\n",
    "\n",
    "        width  = videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
    "        height = videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
    "\n",
    "        # Capture loop \n",
    "        while (key != ord(' ')):        # play video until user presses <space>\n",
    "            # Get the next frame\n",
    "            _, matFrameCapture = videoCapture.read()\n",
    "            if matFrameCapture is None:\n",
    "                # End of video\n",
    "                break\n",
    "\n",
    "            # Rotate if needed\n",
    "            if ROTATE:\n",
    "                _, matFrameDisplay = cv2.rotate(matFrameCapture, cv2.ROTATE_180)\n",
    "            else:\n",
    "                matFrameDisplay = matFrameCapture;\n",
    "\n",
    "            ratio = 480.0 / height\n",
    "            dim = (int(width * ratio), int(height * ratio))\n",
    "            # resize image to 480p for display\n",
    "            matFrameDisplay = cv2.resize(matFrameDisplay, dim)\n",
    "\n",
    "            # Show the image in window named \"robot.mp4\"\n",
    "            cv2.imshow(VIDEO_FILE, matFrameDisplay)\n",
    "            key = cv2.waitKey(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Lab Exercises\n",
    "\n",
    "1. Use <code>waitKey()</code> to wait for the user to press <tt>&lt;space&gt;</tt> to advance to the next frame or 'q' to quit. Check the [documentation for waitKey()](https://docs.opencv.org/4.3.0/d7/dfc/group__highgui.html#ga5628525ad33f52eab17feebcfba38bd7), change the delay parameter to 0 for an infinite wait, and perform the necessary action on a 'spacebar' or 'q' key.\n",
    "\n",
    "2. Display the full 1080p or 720p frame from the video without making the display window too big for your desktop. Take a look at the [documentation for namedWindow()](https://docs.opencv.org/4.3.0/d7/dfc/group__highgui.html#ga5afdf8410934fd099df85c75b2e0888b) and figure out which flags you should use to set up your display window to be resizable but keep the aspect ratio and display the expanded GUI.\n",
    "\n",
    "3. Next we probably want to give the user some useful information. Check out the [documentation for displayOverlay()](https://docs.opencv.org/4.3.0/dc/d46/group__highgui__qt.html#ga704e0387318cd1e7928e6fe17e81d6aa) and add some explanatory information for the user about frame number, total frames, and user control actions.\n",
    "\n",
    "4. Last little detail: currently, if the user closes the window, the program doesn't exit. Modify your program to exit when image display window is closed. Hint: try <code>cv::getWindowProperty(VIDEO_FILE, cv::WND_PROP_VISIBLE)</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting four points for a homography\n",
    "\n",
    "Now, we'd like to allow the user to select four points comprising a square in the real world then compute a rectifying homography for that square, thus rectifying the entire ground plane from the robot's point of view.\n",
    "\n",
    "Check out the [documentation for setMouseCallback()](https://docs.opencv.org/4.3.0/d7/dfc/group__highgui.html#ga89e7806b0a616f6f1d502bd8c183ad3e). Experiment with it until you can get four mouse clicks without interfering with the other GUI functions such as pan/tilt/zoom. Check that you are getting the image coordinates rather than the window coordinates of the mouse clicks.\n",
    "\n",
    "The steps of getting 4 points for homography are:\n",
    " 1. Do the video captures loop\n",
    " 2. press any key to pause the screen and show a new pop-up for showing the pausing image\n",
    " 3. Use the mouse click 4 points.\n",
    " \n",
    "Try the sample code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++ variables\n",
    "\n",
    "Create <tt>Mat</tt> variables to store images and a vector for storing points, then declare a <tt>mouseHandler()</tt> function. To keep\n",
    "things simple, use global variables:\n",
    "\n",
    "    Mat matPauseScreen, matResult, matFinal;\n",
    "    Point point;\n",
    "    vector<Point> pts;\n",
    "    int var = 0;\n",
    "    int drag = 0;\n",
    "\n",
    "    // Create mouse handler function\n",
    "    void mouseHandler(int, int, int, int, void*);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python variables\n",
    "\n",
    "    matResult = None\n",
    "    matFinal = None\n",
    "    matPauseScreen = None\n",
    "\n",
    "    point = (-1, -1)\n",
    "    pts = []\n",
    "    var = 0 \n",
    "    drag = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++ mouse handler\n",
    "\n",
    "    // An OpenCV mouse handler function has 5 parameters\n",
    "    \n",
    "    void mouseHandler(int event, int x, int y, int, void*)\n",
    "    {\n",
    "        if (var >= 4) // If we already have 4 points, do nothing\n",
    "            return;\n",
    "        if (event == EVENT_LBUTTONDOWN) // Left button down\n",
    "        {\n",
    "            drag = 1; // Set it that the mouse is in pressing down mode\n",
    "            matResult = matFinal.clone(); // copy final image to draw image\n",
    "            point = Point(x, y); // memorize current mouse position to point var\n",
    "            if (var >= 1) // if the point has been added more than 1 points, draw a line\n",
    "            {\n",
    "                line(matResult, pts[var - 1], point, Scalar(0, 255, 0, 255), 2); // draw a green line with thickness 2\n",
    "            }\n",
    "            circle(matResult, point, 2, Scalar(0, 255, 0), -1, 8, 0); // draw a current green point\n",
    "            imshow(\"Source\", matResult); // show the current drawing\n",
    "        }\n",
    "        if (event == EVENT_LBUTTONUP && drag) // When Press mouse left up\n",
    "        {\n",
    "            drag = 0; // no more mouse drag\n",
    "            pts.push_back(point);  // add the current point to pts\n",
    "            var++; // increase point number\n",
    "            matFinal = matResult.clone(); // copy the current drawing image to final image\n",
    "            if (var >= 4) // if the homograpy points are done\n",
    "            {\n",
    "                line(matFinal, pts[0], pts[3], Scalar(0, 255, 0, 255), 2); // draw the last line\n",
    "                fillPoly(matFinal, pts, Scalar(0, 120, 0, 20), 8, 0); // draw polygon from points\n",
    "\n",
    "                setMouseCallback(\"Source\", NULL, NULL); // remove mouse event handler\n",
    "            }\n",
    "            imshow(\"Source\", matFinal);\n",
    "        }\n",
    "        if (drag) // if the mouse is dragging\n",
    "        {\n",
    "            matResult = matFinal.clone(); // copy final images to draw image\n",
    "            point = Point(x, y); // memorize current mouse position to point var\n",
    "            if (var >= 1) // if the point has been added more than 1 points, draw a line\n",
    "            {\n",
    "                line(matResult, pts[var - 1], point, Scalar(0, 255, 0, 255), 2); // draw a green line with thickness 2\n",
    "            }\n",
    "            circle(matResult, point, 2, Scalar(0, 255, 0), -1, 8, 0); // draw a current green point\n",
    "            imshow(\"Source\", matResult); // show the current drawing\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python mouse handler\n",
    "\n",
    "    def mouseHandler(event, x, y, flags, param):\n",
    "        global point, pts, var, drag, matFinal, matResult   # call global variable to use in this function\n",
    "\n",
    "        if (var >= 4):                           # if homography points are more than 4 points, do nothing\n",
    "            return\n",
    "        if (event == cv2.EVENT_LBUTTONDOWN):     # When Press mouse left down\n",
    "            drag = 1                             # Set it that the mouse is in pressing down mode\n",
    "            matResult = matFinal.copy()          # copy final image to draw image\n",
    "            point = (x, y)                       # memorize current mouse position to point var\n",
    "            if (var >= 1):                       # if the point has been added more than 1 points, draw a line\n",
    "                cv2.line(matResult, pts[var - 1], point, (0, 255, 0, 255), 2)    # draw a green line with thickness 2\n",
    "            cv2.circle(matResult, point, 2, (0, 255, 0), -1, 8, 0)             # draw a current green point\n",
    "            cv2.imshow(\"Source\", matResult)      # show the current drawing\n",
    "        if (event == cv2.EVENT_LBUTTONUP and drag):  # When Press mouse left up\n",
    "            drag = 0                             # no more mouse drag\n",
    "            pts.append(point)                    # add the current point to pts\n",
    "            var += 1                             # increase point number\n",
    "            matFinal = matResult.copy()          # copy the current drawing image to final image\n",
    "            if (var >= 4):                                                      # if the homograpy points are done\n",
    "                cv2.line(matFinal, pts[0], pts[3], (0, 255, 0, 255), 2)   # draw the last line\n",
    "                cv2.fillConvexPoly(matFinal, np.array(pts, 'int32'), (0, 120, 0, 20))        # draw polygon from points\n",
    "            cv2.imshow(\"Source\", matFinal);\n",
    "        if (drag):                                    # if the mouse is dragging\n",
    "            matResult = matFinal.copy()               # copy final images to draw image\n",
    "            point = (x, y)                   # memorize current mouse position to point var\n",
    "            if (var >= 1):                            # if the point has been added more than 1 points, draw a line\n",
    "                cv2.line(matResult, pts[var - 1], point, (0, 255, 0, 255), 2)    # draw a green line with thickness 2\n",
    "            cv2.circle(matResult, point, 2, (0, 255, 0), -1, 8, 0)         # draw a current green point\n",
    "            cv2.imshow(\"Source\", matResult)           # show the current drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++ <tt>main()</tt>\n",
    "\n",
    "    int main(int argc, char** argv)\n",
    "    {\n",
    "        Mat matFrameCapture;\n",
    "        Mat matFrameDisplay;\n",
    "        int key = -1;\n",
    "\n",
    "        // --------------------- [STEP 1: Make video capture from file] ---------------------\n",
    "        // Open input video file\n",
    "        VideoCapture videoCapture(VIDEO_FILE);\n",
    "        if (!videoCapture.isOpened()) {\n",
    "            cerr << \"ERROR! Unable to open input video file \" << VIDEO_FILE << endl;\n",
    "            return -1;\n",
    "        }\n",
    "\n",
    "        // Capture loop\n",
    "        while (key < 0)        // play video until press any key\n",
    "        {\n",
    "            // Get the next frame\n",
    "            videoCapture.read(matFrameCapture);\n",
    "            if (matFrameCapture.empty()) {   // no more frame capture from the video\n",
    "                // End of video file\n",
    "                break;\n",
    "            }\n",
    "            cvtColor(matFrameCapture, matFrameCapture, COLOR_BGR2BGRA);\n",
    "\n",
    "            // Rotate if needed, some video has output like top go down, so we need to rotate it\n",
    "    #if ROTATE\n",
    "            rotate(matFrameCapture, matFrameCapture, RotateFlags::ROTATE_180);   //rotate 180 degree and put the image to matFrameDisplay\n",
    "    #endif\n",
    "\n",
    "            float ratio = 640.0 / matFrameCapture.cols;\n",
    "            resize(matFrameCapture, matFrameDisplay, cv::Size(), ratio, ratio, INTER_LINEAR);\n",
    "\n",
    "            // Display\n",
    "            imshow(VIDEO_FILE, matFrameDisplay); // Show the image in window named \"robot.mp4\"\n",
    "            key = waitKey(30);\n",
    "\n",
    "            // --------------------- [STEP 2: pause the screen and show an image] ---------------------\n",
    "            if (key >= 0)\n",
    "            {\n",
    "                matPauseScreen = matFrameCapture;  // transfer the current image to process\n",
    "                matFinal = matPauseScreen.clone(); // clone image to final image\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // --------------------- [STEP 3: use mouse handler to select 4 points] ---------------------\n",
    "        if (!matFrameCapture.empty())\n",
    "        {\n",
    "            var = 0;   // reset number of saving points\n",
    "            pts.clear(); // reset all points\n",
    "            namedWindow(\"Source\", WINDOW_AUTOSIZE);  // create a windown named source\n",
    "            setMouseCallback(\"Source\", mouseHandler, NULL); // set mouse event handler \"mouseHandler\" at Window \"Source\"\n",
    "            imshow(\"Source\", matPauseScreen); // Show the image\n",
    "            waitKey(0); // wait until press anykey\n",
    "            destroyWindow(\"Source\"); // destroy the window\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            cout << \"You did not pause the screen before the video finish, the program will stop\" << endl;\n",
    "            return 0;\n",
    "        }\n",
    "\n",
    "        return 0;\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python <tt>\\_\\_main\\_\\_</tt>:\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        global matFinal, matResult, matPauseScreen         # call global variable to use in this function\n",
    "        key = -1;\n",
    "\n",
    "        # --------------------- [STEP 1: Make video capture from file] ---------------------\n",
    "        # Open input video file\n",
    "        videoCapture = cv2.VideoCapture(VIDEO_FILE);\n",
    "        if not videoCapture.isOpened():\n",
    "            print(\"ERROR! Unable to open input video file \", VIDEO_FILE)\n",
    "            sys.exit('Unable to open input video file')\n",
    "\n",
    "        width  = videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
    "        height = videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
    "\n",
    "        # Capture loop \n",
    "        while (key < 0):        # play video until press any key\n",
    "            # Get the next frame\n",
    "            _, matFrameCapture = videoCapture.read()\n",
    "            if matFrameCapture is None:   # no more frame capture from the video\n",
    "                # End of video file\n",
    "                break\n",
    "\n",
    "            # Rotate if needed, some video has output like top go down, so we need to rotate it\n",
    "            if ROTATE:\n",
    "                _, matFrameDisplay = cv2.rotate(matFrameCapture, cv2.ROTATE_180)   #rotate 180 degree and put the image to matFrameDisplay\n",
    "            else:\n",
    "                matFrameDisplay = matFrameCapture;\n",
    "\n",
    "            ratio = 640.0 / width\n",
    "            dim = (int(width * ratio), int(height * ratio))\n",
    "            # resize image to 480 * 640 for showing\n",
    "            matFrameDisplay = cv2.resize(matFrameDisplay, dim)\n",
    "\n",
    "            # Show the image in window named \"robot.mp4\"\n",
    "            cv2.imshow(VIDEO_FILE, matFrameDisplay)\n",
    "            key = cv2.waitKey(30)\n",
    "\n",
    "            # --------------------- [STEP 2: pause the screen and show an image] ---------------------\n",
    "            if (key >= 0):\n",
    "                matPauseScreen = matFrameCapture     # transfer the current image to process\n",
    "                matFinal = matPauseScreen.copy()     # copy image to final image\n",
    "\n",
    "        # --------------------- [STEP 3: use mouse handler to select 4 points] ---------------------\n",
    "        if (matFrameCapture is not None):\n",
    "            var = 0                                             # reset number of saving points\n",
    "            pts.clear()                                         # reset all points\n",
    "            cv2.namedWindow(\"Source\", cv2.WINDOW_AUTOSIZE)      # create a windown named source\n",
    "            cv2.setMouseCallback(\"Source\", mouseHandler)        # set mouse event handler \"mouseHandler\" at Window \"Source\"\n",
    "            cv2.imshow(\"Source\", matPauseScreen)                # Show the image\n",
    "            cv2.waitKey(0)                                      # wait until press anykey\n",
    "            cv2.destroyWindow(\"Source\")                         # destroy the window\n",
    "        else:\n",
    "            print(\"No pause before end of video finish. Exiting.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample result\n",
    "\n",
    "<img src=\"img/lab02-2.PNG\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Lab Exercise\n",
    "\n",
    "Global variables are not good practice in C++ (or any programming language, as far as I know).\n",
    "\n",
    "Figure out how to allocate the state information used by your mouse handler on the heap, and request\n",
    "HighGUI to pass a pointer to the state information to your callback. Instead of\n",
    "\n",
    "    setMouseCallback(\"Source\", mouseHandler, NULL);\n",
    "\n",
    "use\n",
    "\n",
    "    setMouseCallback(\"Source\", mouseHandler, pState);\n",
    "\n",
    "### Calculate Homography\n",
    "\n",
    "Now, given the four points that you've collected from the user, calculate a homography to a rectified square with a desired number of pixels per meter, e.g., 1000. The tiles in the video from last week are 60cm x 60cm.\n",
    "\n",
    "Note that OpenCV doesn't have a <code>null()</code> function like Matlab and Octave. Instead, you'll have to use the SVD operation to get the row of V associated with the smallest singular value of the design matrix. Test that you get the same result from OpenCV's SVD operation and Octave's <code>null()</code> function.\n",
    "\n",
    "Once you've got a homography that works for the selected quadrilateral, you'll want to adjust it by incorporating a translation that maps the bounding box of the transformed image to a valid range starting at 0 for the uppermost Y coordinate and leftmost X coordinate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display rectified image\n",
    "\n",
    "Once you've got that working, you'll want to display a rectified version of the original image in a second HighGUI window as we step through the video. There are two ways to do this: directly (manually) and using <code>cv::warpPerspective()</code>. For this lab's learning outcomes, it would be better for you to do it directly/manually using bilinear interpolation. This will give you a better understanding of how to render image transforms. In your own work later, go ahead and use <code>warpPerspective()</code> or whatever suits you.\n",
    "\n",
    "### Display original and rectified optical flows\n",
    "\n",
    "Once you have the display of the original and ground-plane-rectified images working, add the optical flows from Lab 01 and render them in both images. This will be really useful.\n",
    "\n",
    "Here are examples of using <code>getPerspectiveTransfrom()</code> to get the homograpy and <tt>warpPerspective()</tt> to get the warped image.\n",
    "\n",
    "\n",
    "#### C++\n",
    "\n",
    "Put this code in your main function.\n",
    "\n",
    "    if (pts.size() == 4)\n",
    "    {\n",
    "        Point2f src[4];\n",
    "        for (int i = 0; i < 4; i++)\n",
    "        {\n",
    "            src[i].x = pts[i].x * 1.0;\n",
    "            src[i].y = pts[i].y * 1.0;\n",
    "        }\n",
    "        Point2f reals[4];\n",
    "        reals[0] = Point2f(800.0, 800.0);\n",
    "        reals[1] = Point2f(1000.0, 800.0);\n",
    "        reals[2] = Point2f(1000.0, 1000.0);\n",
    "        reals[3] = Point2f(800.0, 1000.0);\n",
    "\n",
    "        Mat homography_matrix = getPerspectiveTransform(src, reals);\n",
    "        std::cout << \"Estimated Homography Matrix is:\" << std::endl;\n",
    "        std::cout << homography_matrix << std::endl;\n",
    "\n",
    "        // perspective transform operation using transform matrix\n",
    "        cv::warpPerspective(matPauseScreen, matResult, homography_matrix, matPauseScreen.size(), cv::INTER_LINEAR);\n",
    "        imshow(\"Source\", matPauseScreen);\n",
    "        imshow(\"Result\", matResult);\n",
    "\n",
    "        waitKey(0);\n",
    "    }\n",
    "\n",
    "#### Python\n",
    "\n",
    "Here is equivalent Python code.\n",
    "\n",
    "    if (len(pts) == 4):\n",
    "        src = np.array(pts).astype(np.float32)\n",
    "\n",
    "        reals = np.array([(800, 800),\n",
    "                          (1000, 800),\n",
    "                          (1000, 1000),\n",
    "                          (800, 1000)], np.float32)\n",
    "\n",
    "        homography_matrix = cv2.getPerspectiveTransform(src, reals);\n",
    "        print(\"Estimated Homography Matrix is:\")\n",
    "        print(homography_matrix)\n",
    "\n",
    "        # perspective transform operation using transform matrix\n",
    "\n",
    "        h, w, ch = matPauseScreen.shape\n",
    "        matResult = cv2.warpPerspective(matPauseScreen, homography_matrix, (w, h), cv2.INTER_LINEAR)\n",
    "        matPauseScreen = cv2.resize(matPauseScreen, dim)\n",
    "        cv2.imshow(\"Source\", matPauseScreen)\n",
    "        matResult = cv2.resize(matResult, dim)\n",
    "        cv2.imshow(\"Result\", matResult)\n",
    "\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "You should get a result similar to this:\n",
    "\n",
    "<img src=\"img/lab02-3.PNG\" width=\"600\"/>\n",
    "\n",
    "Is this image correct? Let's see what we get during the lab session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Calculate the homography manually using the SVD of the linear system design matrix similar to the null space solution from class.\n",
    "\n",
    "2. Compute the warped image manually using the inverse of the homography and bilinear interpolation in the input image.\n",
    "\n",
    "3. Reuse the homography from your last run: If your program finds a file <tt>homography.yml</tt> in the working directory,\n",
    "   it should read the homography from that file and use it to display the transformed image. For this, you will have to learn\n",
    "   how OpenCV stores data files in YML format using the <tt>FileStorage</tt> class. When the user selects four points in a frame,\n",
    "   output the resulting homography to the data file and re-read that file when the program starts again.\n",
    "   This way, the user only has to do the \"calibration\" once.\n",
    "\n",
    "### What to turn in\n",
    "\n",
    "Write a brief report and turn in using Google Classroom before the next lab. Include your experience with both the in-class exercises\n",
    "and the final exercises.\n",
    "\n",
    "Make a video showing the frames of the original video with optical flows side-by-side with the rectified image and rectified optical flows, put the video online, and point to it on the Piazza discussion board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
